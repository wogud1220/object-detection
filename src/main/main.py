import os, torch
from tqdm import tqdm

from src.main.ensemble_wbf import ensemble_wbf
from src.main.make_csv import make_csv
from src.YOLO.convert_data import convert_data
from src.YOLO.make_yaml import make_yaml
from src.YOLO.make_yolo_dir import make_yolo_dir
from src.datas.data_stratify import data_stratify
from src.datas.data_loader import data_loader
from src.main.make_dataframe import search_data
from src.main.train_summary import train_summary
from src.utils.check_json import check_json
from src.datas.transforms import transforms
from src.utils.change_bbox import change_bbox

from src.main.train_large import train_large
from src.main.train_medium import train_medium

from src.utils.process_annotation import process_annotation
from src.utils.korean import set_korean_font
import globals

# ë°ì´í„° ê¸°ë³¸ ê²½ë¡œ (ì••ì¶• í•´ì œí•œ ìœ„ì¹˜)
BASE_DIR = "../../ai05-level1-project"
JSON_PATH = f"{BASE_DIR}/train_combined.json"

# í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ
TRAIN_IMG_DIR = f"{BASE_DIR}/train_images"
TRAIN_ANN_DIR = f"{BASE_DIR}/train_annotations"
TEST_IMG_DIR = f"{BASE_DIR}/test_images"

YOLO_DIR = f"{BASE_DIR}/yolo_dataset"

def main():
    # í•œê¸€ í°íŠ¸ ì„¤ì •
    set_korean_font()

    # GPU ì„¤ì •
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # ê²½ë¡œ ì„¤ì •
    check_datapath()

    # Annotation files -> í•˜ë‚˜ì˜ jsonìœ¼ë¡œ ë¬¶ê¸°
    train_data, all_json_files = process_annotation(TRAIN_ANN_DIR)

    # iou 0.1 ì´ìƒ, bbox coordinate> img_sizeë“¤ì˜  Bbox ë³€ê²½
    change_bbox()


    # ë°ì´í„° íƒìƒ‰
    images_df, categories_df, annotations_df = search_data(train_data)

    ### FONT ###
    #set_font()
    #add_font()

    # annotationê³¼
    check_json(all_json_files)

    # íŠ¸ëœìŠ¤í¼ ìƒì„±
    train_transform, val_transform = transforms()


    # train, val Stratify
    train_dataset, val_dataset, train_images_df, val_images_df, train_annotations_df, val_annotations_df\
        = data_stratify(images_df, annotations_df, categories_df, train_transform, val_transform, TRAIN_IMG_DIR)


    # data_loader, yolo ë‚´ì¥ dataLoader ì‚¬ìš©í•´ì„œ ì•ˆ ì“¸ë“¯
    train_loader, val_loader = data_loader(train_dataset,val_dataset)


    # make yolo dir
    category_id_mapping, num_classes = make_yolo_dir(categories_df)


    convert_data(train_images_df, train_annotations_df, val_images_df, val_annotations_df, category_id_mapping)

    # make_yaml
    make_yaml(categories_df)


    # train
    # model_large = train_large()
    # model_medium = train_medium()

    #train summary
    train_summary(categories_df, annotations_df, best_model_path="../../models/L-best.pt")
    train_summary(categories_df, annotations_df, best_model_path="../../models/M-best.pt")

    test_images = sorted(os.listdir(TEST_IMG_DIR))

    # ëª¨ë“  test ì´ë¯¸ì§€ì— ëŒ€í•´ ì˜ˆì¸¡ ìˆ˜í–‰
    predictions = {}
    for img_name in tqdm(test_images, desc="ğŸ” ì•™ìƒë¸” ì¶”ë¡  ì¤‘"):
        img_path = os.path.join(TEST_IMG_DIR, img_name)
        boxes, scores, labels = ensemble_wbf(img_path, conf=0.1, iou_thr=0.55)
        predictions[img_name] = {
            "boxes": boxes,
            "scores": scores,
            "labels": labels
        }
    print(f"ì´ {len(predictions)}ê°œì˜ ê²°ê³¼ ì €ì¥ë¨.")


    # Kaggle ì œì¶œìš© CSV íŒŒì¼ ë§Œë“¤ê¸°
    make_csv(predictions, category_id_mapping)

    return


def check_datapath():
    # ì‹¤ì œ í´ë” ë° íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    print("ğŸ“‚ ê²½ë¡œ ì„¤ì •:")
    for name, path in [("BASE_DIR", BASE_DIR),
                       ("TRAIN_IMG_DIR", TRAIN_IMG_DIR),
                       ("TRAIN_ANN_DIR", TRAIN_ANN_DIR),
                       ("TEST_IMG_DIR", TEST_IMG_DIR)]:
        exists = "âœ…" if os.path.exists(path) else "âŒ"
        print(f"{exists} {name}: {path}")


if __name__ == "__main__":
    main()