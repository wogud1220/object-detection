import os
import json
from tqdm import tqdm

from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader

import matplotlib.pyplot as plt
import matplotlib.patches as patches
import matplotlib.image as mpimg
import matplotlib.font_manager as fm
import warnings

from collections import defaultdict

from ultralytics import YOLO
import yaml

from IPython.display import Image as IPImage, display

import pandas as pd
from collections import Counter

import torch

from src.data.PillDataset import PillDataset
from src.utils import util
from src.utils.albumentations_A import train_compose
from src.utils.albumentations_A import val_compose

# ë°ì´í„° ê¸°ë³¸ ê²½ë¡œ (ì••ì¶• í•´ì œí•œ ìœ„ì¹˜)
root_dir="C:/workspace/github/data" #ì„ì‹œ ê²½ë¡œ. ê²½ë¡œ ì •í•´ì§€ë©´ ì‚­ì œ í•„ìš”í•¨.
BASE_DIR = root_dir  #"/content/data" #ì´ë¯¸ì§€ ê²½ë¡œëŠ” ì—¬ê¸°ì— ì„¤ì •.

# í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ
TRAIN_IMG_DIR = f"{BASE_DIR}/train_images"
TRAIN_ANN_DIR = f"{BASE_DIR}/train_annotations"
TEST_IMG_DIR = f"{BASE_DIR}/test_images"

YOLO_DIR = f"{BASE_DIR}/yolo_dataset"

def main():

    """ main """

    """ # ê²½ë¡œ í™•ì¸ """
    check_datapath()

    """ # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì¶œë ¥ """
    show_testimages(TEST_IMG_DIR)

    """ # Annotation íŒŒì¼ ìˆ˜ì§‘ ë° í†µí•© """
    train_data, all_json_files = process_annotation(TRAIN_ANN_DIR)

    """ # ë°ì´í„° íƒìƒ‰ """
    images_df, categories_df, annotations_df = search_data(train_data)

    """ # ì–´ë…¸í…Œì´ì…˜ ì‹œê°í™” """
    process_visualize_annotations(images_df, categories_df, annotations_df)

    """ JSON íŒŒì¼ì„ í™•ì¸ """
    check_json(all_json_files)

    """ ë°ì´í„°ì…‹, ë°ì´í„°ë¡œë” ì²˜ë¦¬ """
    train_images_df, val_images_df, train_annotations_df, val_annotations_df = process_data(images_df, categories_df, annotations_df)

    """ YOLO ë°ì´í„°ì…‹ """
    category_id_mapping, num_classes = process_yolo_dataset(categories_df)

    """ # Train, Val ë°ì´í„° ë³€í™˜ """
    train_success, val_success = convert_data(train_images_df, val_images_df, train_annotations_df, val_annotations_df, category_id_mapping)

    """ í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ ìƒì„± """
    yaml_path = make_class_list(categories_df, num_classes, train_success, val_success)

    """ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± """
    model = make_model()

    """ ëª¨ë¸ í•™ìŠµ """
    make_train(model, yaml_path)

    """ ëª¨ë¸ ê²°ê³¼ """
    predict_model()

def check_datapath():
    # ê²½ë¡œ í™•ì¸
    print("ğŸ“‚ ê²½ë¡œ ì„¤ì • ì™„ë£Œ:")
    print(f"BASE_DIR      : {BASE_DIR}")
    print(f"TRAIN_IMG_DIR : {TRAIN_IMG_DIR}")
    print(f"TEST_IMG_DIR  : {TEST_IMG_DIR}")

    # ì‹¤ì œ í´ë” ë° íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    print("ğŸ“‚ ê²½ë¡œ ì„¤ì •:")
    for name, path in [("BASE_DIR", BASE_DIR),
                       ("TRAIN_IMG_DIR", TRAIN_IMG_DIR),
                       ("TRAIN_ANN_DIR", TRAIN_ANN_DIR),
                       ("TEST_IMG_DIR", TEST_IMG_DIR)]:
        exists = "âœ…" if os.path.exists(path) else "âŒ"
        print(f"{exists} {name}: {path}")

def show_testimages(TEST_IMG_DIR="/content/data/test_images"):
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ í´ë”
    #TEST_IMG_DIR = "/content/data/test_images"

    # íŒŒì¼ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
    test_files = sorted(os.listdir(TEST_IMG_DIR))

    # ì´ë¯¸ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
    print(f"ì´ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê°œìˆ˜: {len(test_files)}")
    print("ì˜ˆì‹œ íŒŒì¼ëª…:", test_files[:5])

    # ì•ë¶€ë¶„ 9ê°œë§Œ ë¯¸ë¦¬ë³´ê¸°
    sample_files = test_files[:9]

    # ì‹œê°í™”
    plt.figure(figsize=(12, 12))
    for i, img_name in enumerate(sample_files):
        img_path = os.path.join(TEST_IMG_DIR, img_name)
        img = mpimg.imread(img_path)
        plt.subplot(3, 3, i + 1)
        plt.imshow(img)
        plt.title(img_name, fontsize=9)
        plt.axis("off")

    plt.tight_layout()
    plt.show()

# Annotation íŒŒì¼ ìˆ˜ì§‘ ë° í†µí•©
def process_annotation(TRAIN_ANN_DIR="/content/data/train_annotations"):
    #TRAIN_ANN_DIR = "/content/data/train_annotations"

    # ëª¨ë“  JSON íŒŒì¼ ì°¾ê¸°
    all_json_files = []
    for root, dirs, files in os.walk(TRAIN_ANN_DIR):
        for file in files:
            if file.endswith('.json'):
                all_json_files.append(os.path.join(root, file))

    print(f"âœ… ì´ JSON íŒŒì¼ ê°œìˆ˜: {len(all_json_files)}")
    print(f"ì˜ˆì‹œ íŒŒì¼:\n{all_json_files[0]}")

    # file_nameì„ í‚¤ë¡œ í•˜ì—¬ ë°ì´í„° ìˆ˜ì§‘
    images_dict = {}  # {file_name: image_info}
    annotations_by_image = defaultdict(list)  # {file_name: [annotations]}
    categories_dict = {}  # {category_id: category_name}

    print("\nğŸ“Š JSON íŒŒì¼ ì²˜ë¦¬ ì¤‘...")
    for idx, json_path in enumerate(all_json_files):
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # ì´ë¯¸ì§€ ì •ë³´ ìˆ˜ì§‘
            if 'images' in data and len(data['images']) > 0:
                img = data['images'][0]
                file_name = img['file_name']

                # ì´ë¯¸ì§€ ì •ë³´ëŠ” í•œ ë²ˆë§Œ ì €ì¥ (ì¤‘ë³µ ë°©ì§€)
                if file_name not in images_dict:
                    images_dict[file_name] = {
                        'file_name': file_name,
                        'width': img.get('width'),
                        'height': img.get('height'),
                    }

            # Annotation ìˆ˜ì§‘ (ê°™ì€ file_nameë¼ë¦¬ ë¬¶ìŒ)
            if 'annotations' in data:
                for ann in data['annotations']:
                    annotations_by_image[file_name].append({
                        'category_id': ann['category_id'],
                        'bbox': ann['bbox'],
                        'area': ann.get('area', ann['bbox'][2] * ann['bbox'][3]),
                        'iscrowd': ann.get('iscrowd', 0)
                    })

            # ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘
            if 'categories' in data:
                for cat in data['categories']:
                    categories_dict[cat['id']] = cat['name']

            # ì§„í–‰ìƒí™© ì¶œë ¥ (500ê°œë§ˆë‹¤)
            if (idx + 1) % 500 == 0:
                print(f"  ì²˜ë¦¬ ì¤‘... {idx + 1}/{len(all_json_files)}")

        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ({os.path.basename(json_path)}): {e}")
            continue

    # COCO í˜•ì‹ìœ¼ë¡œ ìµœì¢… ì •ë¦¬
    combined_data = {
        'images': [],
        'annotations': [],
        'categories': []
    }

    image_id = 0
    annotation_id = 0

    print("\nğŸ”— ì´ë¯¸ì§€ì™€ Annotation ì—°ê²° ì¤‘...")
    for file_name, img_info in images_dict.items():
        # ì´ë¯¸ì§€ ì¶”ê°€
        img_info['id'] = image_id
        combined_data['images'].append(img_info)

        # í•´ë‹¹ ì´ë¯¸ì§€ì˜ ëª¨ë“  annotation ì¶”ê°€
        for ann in annotations_by_image[file_name]:
            combined_data['annotations'].append({
                'id': annotation_id,
                'image_id': image_id,
                'category_id': ann['category_id'],
                'bbox': ann['bbox'],
                'area': ann['area'],
                'iscrowd': ann['iscrowd']
            })
            annotation_id += 1

        image_id += 1

    # ì¹´í…Œê³ ë¦¬ ì •ë¦¬
    combined_data['categories'] = [
        {'id': cat_id, 'name': cat_name}
        for cat_id, cat_name in sorted(categories_dict.items())
    ]

    print(f"\nâœ… í†µí•© ì™„ë£Œ!")
    print(f"  - ì´ ì´ë¯¸ì§€: {len(combined_data['images'])}")
    print(f"  - ì´ Annotation: {len(combined_data['annotations'])}")
    print(f"  - ì´ ì¹´í…Œê³ ë¦¬: {len(combined_data['categories'])}")
    print(f"  - í‰ê·  ì´ë¯¸ì§€ë‹¹ ê°ì²´ ìˆ˜: {len(combined_data['annotations']) / len(combined_data['images']):.2f}ê°œ")

    # í†µí•© ë°ì´í„° ì €ì¥
    train_data = combined_data

    # ë‚˜ì¤‘ì— ì¬ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ íŒŒì¼ë¡œ ì €ì¥
    output_path = f"{BASE_DIR}/train_combined.json"
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(train_data, f, ensure_ascii=False)
    print(f"\nğŸ’¾ í†µí•© íŒŒì¼ ì €ì¥: {output_path}")

    return train_data, all_json_files

def search_data(train_data):
    # ë°ì´í„° íƒìƒ‰

    # ì´ë¯¸ì§€ ì •ë³´
    images_df = pd.DataFrame(train_data['images'])
    print(f"ğŸ“· ì´ ì´ë¯¸ì§€ ê°œìˆ˜: {len(images_df)}")
    print(images_df.head())

    # ì¹´í…Œê³ ë¦¬ ì •ë³´
    categories_df = pd.DataFrame(train_data['categories'])
    print(f"\nğŸ·ï¸ ì´ ì¹´í…Œê³ ë¦¬(ì•Œì•½ ì¢…ë¥˜): {len(categories_df)}")
    print(categories_df)

    # Annotation ì •ë³´
    annotations_df = pd.DataFrame(train_data['annotations'])
    print(f"\nğŸ“¦ ì´ Annotation ê°œìˆ˜: {len(annotations_df)}")
    print(annotations_df.head())

    # ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
    category_counts = Counter(annotations_df['category_id'])
    print("\nğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ê°ì²´ ê°œìˆ˜:")
    for cat_id, count in sorted(category_counts.items()):
        cat_name = categories_df[categories_df['id'] == cat_id]['name'].values[0]
        print(f"  Class {cat_id} ({cat_name}): {count}ê°œ")

    # ì´ë¯¸ì§€ë‹¹ ê°ì²´ ìˆ˜ ë¶„í¬
    img_obj_counts = annotations_df.groupby('image_id').size()
    print(f"\nğŸ“ˆ ì´ë¯¸ì§€ë‹¹ ê°ì²´ ìˆ˜ í†µê³„:")
    print(f"  - í‰ê· : {img_obj_counts.mean():.2f}ê°œ")
    print(f"  - ìµœì†Œ: {img_obj_counts.min()}ê°œ")
    print(f"  - ìµœëŒ€: {img_obj_counts.max()}ê°œ")

    return images_df, categories_df, annotations_df

def setting_font():
    #path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'  # ë‚˜ëˆ” ê³ ë”•
    path = 'C:/Windows/Fonts/ë‚˜ëˆ”ê³ ë”•/NanumGothic.ttf'  # ë‚˜ëˆ” ê³ ë”•
    font_name = fm.FontProperties(fname=path, size=10).get_name()  # ê¸°ë³¸ í°íŠ¸ ì‚¬ì´ì¦ˆ : 10
    plt.rc('font', family=font_name)

    fm.fontManager.addfont(path)

def process_visualize_annotations(images_df, categories_df, annotations_df):
    valid_image_ids = annotations_df['image_id'].unique()
    print(f"ğŸ“Š Annotationì´ ìˆëŠ” ì´ë¯¸ì§€: {len(valid_image_ids)}ê°œ")
    print(f"ğŸ“Š ì „ì²´ ì´ë¯¸ì§€: {len(images_df)}ê°œ")

    if len(valid_image_ids) < len(images_df):
        print(f"âš ï¸ Annotationì´ ì—†ëŠ” ì´ë¯¸ì§€: {len(images_df) - len(valid_image_ids)}ê°œ")

    # ê°ì²´ ìˆ˜ë³„ ë¶„í¬ ë‹¤ì‹œ í™•ì¸
    img_obj_counts_df = annotations_df.groupby('image_id').size().reset_index(name='count')
    print(f"\nğŸ“Š ê°ì²´ ìˆ˜ë³„ ì´ë¯¸ì§€ ë¶„í¬:")
    print(img_obj_counts_df['count'].value_counts().sort_index())

    # ì—¬ëŸ¬ ê°ì²´ê°€ ìˆëŠ” ì´ë¯¸ì§€ ì°¾ê¸°
    multi_obj_images = img_obj_counts_df[img_obj_counts_df['count'] >= 2]
    print(f"\nâœ… 2ê°œ ì´ìƒ ê°ì²´: {len(multi_obj_images)}ê°œ")

    # ì‹œê°í™”
    print("\nğŸ¨ ìƒ˜í”Œ ì´ë¯¸ì§€ ì‹œê°í™” (í¬ê¸° ì¡°ì •):")

    if len(multi_obj_images) > 0:
        # ì—¬ëŸ¬ ê°ì²´ê°€ ìˆëŠ” ì´ë¯¸ì§€ ìš°ì„ 
        print("ì—¬ëŸ¬ ê°ì²´ê°€ ìˆëŠ” ì´ë¯¸ì§€:")
        sample_ids = multi_obj_images['image_id'].sample(min(3, len(multi_obj_images))).values
    else:
        # ì—†ìœ¼ë©´ ëœë¤
        print("ëœë¤ ìƒ˜í”Œ:")
        sample_ids = img_obj_counts_df['image_id'].sample(min(3, len(img_obj_counts_df))).values

    for img_id in sample_ids:
        util.visualize_annotations(TRAIN_IMG_DIR,
                          images_df,
                          annotations_df,
                          categories_df,
                                   img_id, figsize=(8, 8))

def check_json(all_json_files):
    #  ì›ë³¸ JSON íŒŒì¼ì—ì„œ ì§ì ‘ í™•ì¸

    # Image ID 1023ì˜ íŒŒì¼ëª…ìœ¼ë¡œ ì›ë³¸ JSON ì°¾ê¸°
    target_file = "K-001900-016548-031705-033208_0_2_0_2_75_000_200.png"

    print(f"ğŸ” {target_file}ì— í•´ë‹¹í•˜ëŠ” ì›ë³¸ JSON íŒŒì¼ë“¤:\n")

    json_count = 0
    for json_path in all_json_files:
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            if 'images' in data and len(data['images']) > 0:
                if data['images'][0]['file_name'] == target_file:
                    json_count += 1
                    print(f"[{json_count}] {os.path.basename(json_path)}")

                    if 'annotations' in data:
                        for ann in data['annotations']:
                            cat_id = ann['category_id']
                            # categoriesì—ì„œ ì´ë¦„ ì°¾ê¸°
                            cat_name = "Unknown"
                            if 'categories' in data:
                                for cat in data['categories']:
                                    if cat['id'] == cat_id:
                                        cat_name = cat['name']
                                        break
                            bbox = ann['bbox']
                            print(f"    - {cat_name} (ID: {cat_id})")
                            print(f"      BBox: {bbox}")
                    print()
        except:
            continue

    print(f"âœ… ì´ {json_count}ê°œì˜ JSON íŒŒì¼ ë°œê²¬")
    print(f"\nğŸ’¡ ê²°ë¡ : ì›ë³¸ ë°ì´í„°ì—ë„ {json_count}ê°œì˜ annotationë§Œ ìˆìŒ")
    print("    â†’ ë³‘í•© ê³¼ì •ì€ ì •ìƒì´ë©°, ë°ì´í„°ì…‹ ìì²´ê°€ ì´ë ‡ê²Œ ì œê³µ")

def process_data(images_df, categories_df, annotations_df):
    # Train/Val Split
    train_ids, val_ids = train_test_split(
        images_df['id'].values,
        test_size=0.2,
        random_state=42
    )

    train_images_df = images_df[images_df['id'].isin(train_ids)].reset_index(drop=True)
    val_images_df = images_df[images_df['id'].isin(val_ids)].reset_index(drop=True)

    train_annotations_df = annotations_df[annotations_df['image_id'].isin(train_ids)]
    val_annotations_df = annotations_df[annotations_df['image_id'].isin(val_ids)]

    train_transform = train_compose()
    val_transform = val_compose()

    # Dataset ìƒì„±
    train_dataset = PillDataset(
        TRAIN_IMG_DIR,
        train_images_df,
        train_annotations_df,
        categories_df,
        transform=train_transform
    )

    val_dataset = PillDataset(
        TRAIN_IMG_DIR,
        val_images_df,
        val_annotations_df,
        categories_df,
        transform=val_transform
    )

    # # Collate í•¨ìˆ˜
    # def collate_fn(batch):
    #     return tuple(zip(*batch))

    # DataLoader
    train_loader = DataLoader(
        train_dataset,
        batch_size=4,
        shuffle=True,
        collate_fn=collate_fn,
        num_workers=2
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=4,
        shuffle=False,
        collate_fn=collate_fn,
        num_workers=2
    )

    print("âœ… ë°ì´í„° ì¦ê°•ì´ ì ìš©ëœ Dataset/DataLoader ìƒì„± ì™„ë£Œ!")
    print(f"  - Train: {len(train_dataset)}ê°œ")
    print(f"  - Val: {len(val_dataset)}ê°œ")
    print(f"  - Train batches: {len(train_loader)}")
    print(f"  - Val batches: {len(val_loader)}")

    # ìƒ˜í”Œ í™•ì¸
    images, targets = next(iter(train_loader))
    print(f"\nâœ… ìƒ˜í”Œ ë°°ì¹˜:")
    print(f"  - Batch size: {len(images)}")
    print(f"  - ì´ë¯¸ì§€ shape: {images[0].shape}")
    print(f"  - ê°ì²´ ìˆ˜: {len(targets[0]['labels'])}ê°œ")

    return train_images_df, val_images_df, train_annotations_df, val_annotations_df

# Collate í•¨ìˆ˜
def collate_fn(batch):
    return tuple(zip(*batch))

def process_yolo_dataset(categories_df):
    # YOLO ë°ì´í„°ì…‹ í´ë” êµ¬ì¡° ìƒì„±
    #YOLO_DIR = f"{BASE_DIR}/yolo_dataset"
    os.makedirs(f"{YOLO_DIR}/images/train", exist_ok=True)
    os.makedirs(f"{YOLO_DIR}/images/val", exist_ok=True)
    os.makedirs(f"{YOLO_DIR}/labels/train", exist_ok=True)
    os.makedirs(f"{YOLO_DIR}/labels/val", exist_ok=True)

    print("âœ… YOLO í´ë” êµ¬ì¡° ìƒì„± ì™„ë£Œ!")

    # ì¹´í…Œê³ ë¦¬ IDë¥¼ 0ë¶€í„° ì‹œì‘í•˜ë„ë¡ ë§¤í•‘
    category_id_mapping = {cat_id: idx for idx, cat_id in enumerate(sorted(categories_df['id'].unique()))}
    num_classes = len(category_id_mapping)

    print(f"ğŸ“Š ì´ í´ë˜ìŠ¤ ìˆ˜: {num_classes}ê°œ")
    print(f"ì¹´í…Œê³ ë¦¬ ë§¤í•‘ (ì²˜ìŒ 5ê°œ): {dict(list(category_id_mapping.items())[:5])}")

    return category_id_mapping, num_classes

def convert_data(train_images_df, val_images_df, train_annotations_df, val_annotations_df, category_id_mapping):
    # Train ë°ì´í„° ë³€í™˜
    print("ğŸ“ Train ë°ì´í„° ë³€í™˜ ì¤‘...")
    train_success = 0
    for _, img_info in tqdm(train_images_df.iterrows(), total=len(train_images_df)):
        if util.convert_to_yolo_format(
                img_info,
                train_annotations_df,
                f"{YOLO_DIR}/images/train",
                f"{YOLO_DIR}/labels/train",
                category_id_mapping,
                TRAIN_IMG_DIR
        ):
            train_success += 1

    print(f"âœ… Train ë°ì´í„° ë³€í™˜ ì™„ë£Œ: {train_success}/{len(train_images_df)}ê°œ")

    # Val ë°ì´í„° ë³€í™˜
    print("\nğŸ“ Val ë°ì´í„° ë³€í™˜ ì¤‘...")
    val_success = 0
    for _, img_info in tqdm(val_images_df.iterrows(), total=len(val_images_df)):
        if util.convert_to_yolo_format(
                img_info,
                val_annotations_df,
                f"{YOLO_DIR}/images/val",
                f"{YOLO_DIR}/labels/val",
                category_id_mapping,
                TRAIN_IMG_DIR
        ):
            val_success += 1

    print(f"âœ… Val ë°ì´í„° ë³€í™˜ ì™„ë£Œ: {val_success}/{len(val_images_df)}ê°œ")

    return train_success, val_success

def make_class_list(categories_df, num_classes, train_success, val_success):
    # í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    class_names = []
    for cat_id in sorted(categories_df['id'].unique()):
        cat_name = categories_df[categories_df['id'] == cat_id]['name'].values[0]
        class_names.append(cat_name)

    # data.yaml ë‚´ìš©
    data_yaml = {
        'path': YOLO_DIR,
        'train': 'images/train',
        'val': 'images/val',
        'nc': num_classes,
        'names': class_names
    }

    # ì €ì¥
    yaml_path = f"{YOLO_DIR}/data.yaml"
    with open(yaml_path, 'w', encoding='utf-8') as f:
        yaml.dump(data_yaml, f, allow_unicode=True, sort_keys=False)

    print("âœ… data.yaml ìƒì„± ì™„ë£Œ!")
    print(f"ê²½ë¡œ: {yaml_path}")
    print(f"\nğŸ“‹ ì„¤ì • ë‚´ìš©:")
    print(f"  - Train ì´ë¯¸ì§€: {train_success}ê°œ")
    print(f"  - Val ì´ë¯¸ì§€: {val_success}ê°œ")
    print(f"  - í´ë˜ìŠ¤ ìˆ˜: {num_classes}ê°œ")
    print(f"  - í´ë˜ìŠ¤ ì˜ˆì‹œ: {class_names[:3]}")

    return yaml_path

def make_model():
    model = YOLO('yolov8m.pt')
    return model

def make_train(model, yaml_path):
    # í•™ìŠµ íŒŒë¼ë¯¸í„°
    results = model.train(
        data=yaml_path,
        epochs=1,  ##20,  # ìµœëŒ€ 20 ì—í­  ##ì„ì‹œë¡œ ì—í­ì„ 1ë¡œ ì„¤ì •í•¨.
        imgsz=800,  # ì´ë¯¸ì§€ í¬ê¸°
        batch=8,  # ë°°ì¹˜ í¬ê¸°
        patience=10,  # Early stopping patience (10 ì—í­ ë™ì•ˆ ê°œì„  ì—†ìœ¼ë©´ ì¤‘ë‹¨)
        save=True,  # ëª¨ë¸ ì €ì¥
        device='cpu', ##0 if torch.cuda.is_available() else 'cpu',  # GPU ìë™ ì„ íƒ ##ì„ì‹œë¡œ cpuë¡œ ì„¤ì •í•¨.
        project=f'{BASE_DIR}/yolo_runs',  # ê²°ê³¼ ì €ì¥ í´ë”
        name='pill_detection',
        exist_ok=True,
        pretrained=True,
        optimizer='Adam',
        lr0=0.001,  # ì´ˆê¸° learning rate
        lrf=0.01,  # ìµœì¢… learning rate
        momentum=0.937,
        weight_decay=0.0005,
        warmup_epochs=3,
        box=7.5,  # box loss gain
        cls=0.5,  # cls loss gain
        dfl=1.5,  # dfl loss gain
        label_smoothing=0.0,
        val=True,  # Validation ìˆ˜í–‰
        plots=True,  # í•™ìŠµ ê·¸ë˜í”„ ìë™ ìƒì„±
        verbose=True
    )

    print("\n í•™ìŠµ ì™„ë£Œ!")
    print(f" ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {BASE_DIR}/yolo_runs/pill_detection")

def predict_model():
    # ê²°ê³¼ ë””ë ‰í„°ë¦¬ ì„¤ì •
    result_dir = f"{BASE_DIR}/yolo_runs/pill_detection"

    print("ğŸ“ˆ YOLOv8 í•™ìŠµ ê²°ê³¼ ìš”ì•½")
    print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

    # 1ï¸âƒ£ Loss ê·¸ë˜í”„
    loss_img = f"{result_dir}/results.png"
    if os.path.exists(loss_img):
        print("\n1. ğŸ”¹ Loss ë³€í™” ê·¸ë˜í”„")
        display(IPImage(filename=loss_img))
    else:
        print("âŒ Loss ê·¸ë˜í”„(results.png)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # 2ï¸âƒ£ Confusion Matrix
    cm_img = f"{result_dir}/confusion_matrix.png"
    if os.path.exists(cm_img):
        print("\n2. ğŸ”¹ Confusion Matrix")
        display(IPImage(filename=cm_img))
    else:
        print("âŒ Confusion Matrix ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # 3ï¸âƒ£ Validation ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ
    pred_img = f"{result_dir}/val_batch0_pred.jpg"
    if os.path.exists(pred_img):
        print("\n3. ğŸ”¹ Validation ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ")
        display(IPImage(filename=pred_img))
    else:
        print("âŒ ì˜ˆì¸¡ ê²°ê³¼ ì´ë¯¸ì§€(val_batch0_pred.jpg)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # 4ï¸âƒ£ Best ëª¨ë¸ ê²½ë¡œ
    best_model = f"{result_dir}/weights/best.pt"
    print(f"\nâœ… Best ëª¨ë¸ ê²½ë¡œ:\n{best_model if os.path.exists(best_model) else 'âŒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.'}")

if __name__ == "__main__":
    main()